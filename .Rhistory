SSU <- sahdd
SS[,"chd"] <- as.factor(SS[,"chd"])
SSU[,"chd"] <- as.factor(SSU[,"chd"])
SSU[,"famhist"] <- as.factor(SSU[,"famhist"])
# or SS$chd <- as.factor(SS$chd)
str(SS)
str(SSU)
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(10))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(10))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10 bag = T)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 10, bag = T)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time to execute 28 seconds without console, 29.5 with
end_time <- Sys.time()
end_time - start_time
library(dplyr)
library(tidytext)
library(tm)
library(wordcloud)
library(stringr)
library(gutenbergr)
gutenberg_works(str_detect(title, "Frankenstein"))
gutenberg_works(str_detect(title, "Cthulhu"))
gutenberg_works(str_detect(title, "Call"))
gutenberg_works(str_detect(title, "Cthulhu"))
gutenberg_works(str_detect(title, "Sleepy"))
sleepy <- gutenberg_download(41)
sleepy
sleepy%>%
unnest_tokens(words,text)
words_df <- sleepy%>%
unnest_tokens(words,text)
words_df <- words_df%>%
filter(!(words %in% stop_words$word))
words_df%>%
group_by(words)%>%
summarize(count = n())%>%
words_df%>%
group_by(words)%>%
summarize(count = n())
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
wordcloud(word_freq$words, word_freq$count, min.freq = 35)
wordcloud(word_freq$words, word_freq$count, min.freq = 10)
gutenberg_works(str_detect(title, "Usher"))
sleepy <- gutenberg_download(932)
sleepy
words_df <- sleepy%>%
unnest_tokens(words,text)
words_df <- words_df%>%
filter(!(words %in% stop_words$word))
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
wordcloud(word_freq$words, word_freq$count, min.freq = 10)
gutenberg_works(str_detect(title, "Dunwhich"))
gutenberg_works(str_detect(title, "Mountains"))
gutenberg_works(str_detect(title, "Madness"))
gutenberg_works(str_detect(title, "Madness"))
gutenberg_works(str_detect(title, "Hyde"))
gutenberg_works(str_detect(title, "Frankenstein"))
gutenberg_works(str_detect(title, "Hyde"))
gutenberg_works(str_detect(title, "Hyde"))
sleepy <- gutenberg_download(42)
sleepy
words_df <- sleepy%>%
unnest_tokens(words,text)
words_df <- words_df%>%
filter(!(words %in% stop_words$word))
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
wordcloud(word_freq$words, word_freq$count, min.freq = 10)
wordcloud(word_freq$words, word_freq$count, min.freq = 20)
gutenberg_works(str_detect(title, "Dracula"))
sleepy <- gutenberg_download(345)
sleepy
words_df <- sleepy%>%
unnest_tokens(words,text)
words_df <- words_df%>%
filter(!(words %in% stop_words$word))
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
wordcloud(word_freq$words, word_freq$count, min.freq = 20)
wordcloud(word_freq$words, word_freq$count, min.freq = 35)
wordcloud(word_freq$words, word_freq$count, min.freq = 45)
wordcloud(word_freq$words, word_freq$count, min.freq = 50)
wordcloud(word_freq$words, word_freq$count, min.freq = 60)
wordcloud(word_freq$words, word_freq$count, min.freq = 60)
require(caret)
require(e1071)
set.seed(7);
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
SS <- cbind(sahdd["chd"], scale(sahdd[,c(-1,-6,-11)]) )
SSU <- sahdd
SS[,"chd"] <- as.factor(SS[,"chd"])
SSU[,"chd"] <- as.factor(SSU[,"chd"])
SSU[,"famhist"] <- as.factor(SSU[,"famhist"])
str(SS)
str(SSU)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 1, maxit = 200, repeats = 10)
Accuracies[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))
Accuracies2 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-10, maxit = 200, repeats = 10)
Accuracies2[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies2)
acclen = length(na.omit(Accuracies2))
plot(density(Accuracies2), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies3 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 50, repeats = 10)
Accuracies3[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies3)
acclen = length(na.omit(Accuracies3))
plot(density(Accuracies3), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies4 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 500, repeats = 10)
Accuracies4[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies4)
acclen = length(na.omit(Accuracies4))
plot(density(Accuracies4), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies5 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 1)
Accuracies5[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies5)
acclen = length(na.omit(Accuracies5))
plot(density(Accuracies5), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies6 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 50)
Accuracies6[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies6)
acclen = length(na.omit(Accuracies6))
plot(density(Accuracies6), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies7 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-8, maxit = 50, repeats = 1)
Accuracies7[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies7)
acclen = length(na.omit(Accuracies7))
plot(density(Accuracies7), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies8 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 1, maxit = 500, repeats = 50)
Accuracies8[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies8)
acclen = length(na.omit(Accuracies8))
plot(density(Accuracies8), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies9 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 1, maxit = 500, repeats = 10)
Accuracies9[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies9)
acclen = length(na.omit(Accuracies9))
plot(density(Accuracies9), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Accuracies10 <- c(0.00)
for (i in seq(50))
{
inTrain <- createDataPartition(SSU$chd, p = .80, list = FALSE)
SS.navg <- avNNet(SS[c(2:9)], SS$chd, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 50, repeats = 1)
Accuracies10[i] <- confusionMatrix(SS$chd[-inTrain], predict(SS.navg, SS[-inTrain,], type = "class"))$overall["Accuracy"]
}
summary(Accuracies10)
acclen = length(na.omit(Accuracies10))
plot(density(Accuracies10), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells)
H4A <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(H4A[,c(5:61,63,67:80)]);
H4A$PopSex <- as.factor(H4A$PopSex);
H4AS <- cbind(H4A["PopSex"], scale(H4A[2:72]) )
summary(H4AS)
AccuraciesB <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 200, repeats = 10)
AccuraciesB[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB)
acclen = length(na.omit(AccuraciesB))
plot(density(AccuraciesB), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))
AccuraciesB2 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-8, maxit
= 200, repeats = 10)
AccuraciesB2[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB2)
acclen = length(na.omit(AccuraciesB2))
plot(density(AccuraciesB2), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB3 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 1, maxit
= 200, repeats = 10)
AccuraciesB3[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB3)
acclen = length(na.omit(AccuraciesB3))
plot(density(AccuraciesB3), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))
AccuraciesB4 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 50, repeats = 10)
AccuraciesB4[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB4)
acclen = length(na.omit(AccuraciesB4))
plot(density(AccuraciesB4), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB5 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 500, repeats = 10)
AccuraciesB5[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB5)
acclen = length(na.omit(AccuraciesB5))
plot(density(AccuraciesB5), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB6 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 200, repeats = 1)
AccuraciesB6[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB6)
acclen = length(na.omit(AccuraciesB6))
plot(density(AccuraciesB6), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB7 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 200, repeats = 50)
AccuraciesB7[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB7)
acclen = length(na.omit(AccuraciesB7))
plot(density(AccuraciesB7), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB8 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-8, maxit
= 50, repeats = 1)
AccuraciesB8[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB8)
acclen = length(na.omit(AccuraciesB8))
plot(density(AccuraciesB8), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB9 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 1, maxit
= 500, repeats = 50)
AccuraciesB9[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB9)
acclen = length(na.omit(AccuraciesB9))
plot(density(AccuraciesB9), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
AccuraciesB10 <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4AS$PopSex, p = .80, list = FALSE)
H4AS.navg <- avNNet(H4AS[c(2:10)], H4AS$PopSex, data = H4AS, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit
= 500, repeats = 50)
AccuraciesB10[i] <- confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))$overall["Accuracy"]
}
summary(AccuraciesB10)
acclen = length(na.omit(AccuraciesB10))
plot(density(AccuraciesB10), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
confusionMatrix(H4AS$PopSex[-inTrain], predict(H4AS.navg, H4AS[-inTrain,], type =
"class"))
gutenberg_works(str_detect(title, "Dracula"))
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
word_freq
library(dplyr)
library(tidytext)
library(tm)
library(wordcloud)
library(stringr)
library(gutenbergr)
gutenberg_works(str_detect(title, "Dracula"))
Dracula <- gutenberg_download(345)
words_df <- Dracula%>%
unnest_tokens(words,text)
words_df <- words_df%>%
filter(!(words %in% stop_words$word))
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
wordcloud(word_freq$words, word_freq$count, min.freq = 60)
word_freq
word_freq <- words_df%>%
group_by(words)%>%
summarize(count = n())
word_freq
words_df
print(word_freq)
setwd("C:/Users/Andrew/Desktop/Dracula Wordcloud")
library(tidytext)
sentiments
get_sentiments('nrc')
get_sentiments('bing')
get_sentiments('afinn')
nrc <- get_sentiments('nrc')
nrc
nrc%>%
filter(sentiment == 'fear')
fear <- nrc%>%
filter(sentiment == 'fear')
tail(fear)
dracula <- gutenberg_download(345)
dracula
dracula%>%
unnest_tokens(word, text)
dracula_words <- dracula%>%
unnest_tokens(word, text)
dracula_words%>%
filter(words %in% fear$word)
inner_join(fear, dracula_words)  #finds words that are similar between both dataframe.  If it does not exist it is dropped.
dracula_fear <- inner_join(fear, dracula_words)  #finds words that are similar between both dataframe.  If it does not exist it is dropped.
dracula_fear%>%
group_by(word)%>%
summarize(count = n())
dracula_freq <- dracula_fear%>%
group_by(word)%>%
summarize(count = n())
wordcloud(dracula_fear$word, dracula_freq$count, min.freq = 5)
dracula_fear
wordcloud(dracula_freq$word, dracula_freq$count, min.freq = 5)
wordcloud(dracula_freq$word, dracula_freq$count, min.freq = 10)
wordcloud(dracula_freq$word, dracula_freq$count, min.freq = 10)
wordcloud(dracula_freq$word, dracula_freq$count, min.freq = 25)
wordcloud(dracula_freq$word, dracula_freq$count, min.freq = 15)
